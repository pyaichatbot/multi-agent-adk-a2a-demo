# ğŸ§ª SageAI MCP Server Test Suite

## **Comprehensive Testing Without Docker or Server**

This test suite provides comprehensive testing of the SageAI MCP Server without requiring Docker or running the MCP server. All tests run locally and test individual components directly.

---

## **ğŸ“‹ Test Suites**

### **1. Policy Engine Standalone Tests**
- **File**: `test_policy_engine_standalone.py`
- **Purpose**: Test policy engine functionality in isolation
- **Coverage**: Policy evaluation, parameter validation, rate limiting, violation recording, compliance metrics, audit trail

### **2. MCP Tools Direct Tests**
- **File**: `test_mcp_tools_direct.py`
- **Purpose**: Test MCP tools directly without server
- **Coverage**: Database tools, analytics tools, document tools, system tools, SageAI agent tools, SageAI tool tools

### **3. SageAI Integration Tests**
- **File**: `test_sageai_integration.py`
- **Purpose**: Test SageAI platform integration
- **Coverage**: SageAI agent calls, SageAI tool calls, policy enforcement, compliance monitoring

### **4. Comprehensive Test Runner**
- **File**: `run_all_tests.py`
- **Purpose**: Run all test suites and generate comprehensive reports
- **Features**: Quick smoke tests, detailed reporting, JSON output

---

## **ğŸš€ Quick Start**

### **Run All Tests**
```bash
cd enterprise-mcp-server/tests
python run_all_tests.py
```

### **Run Quick Smoke Tests**
```bash
python run_all_tests.py --quick
```

### **Run Individual Test Suites**
```bash
# Policy Engine Tests
python test_policy_engine_standalone.py

# MCP Tools Tests
python test_mcp_tools_direct.py

# SageAI Integration Tests
python test_sageai_integration.py
```

---

## **ğŸ”§ Test Environment Setup**

### **Automatic Setup**
All tests automatically set up their own test environment with:
- **Mock SageAI Authentication**: Simulated token validation
- **Mock SageAI API Responses**: Simulated platform responses
- **Mock Policy Configuration**: Test policy rules
- **Mock Rate Limiting**: Simulated rate limiting behavior

### **No External Dependencies**
- âœ… **No Docker Required**: All tests run locally
- âœ… **No Server Required**: Direct component testing
- âœ… **No Database Required**: Mock data and responses
- âœ… **No Redis Required**: Simulated rate limiting
- âœ… **No Network Required**: All API calls mocked

---

## **ğŸ“Š Test Coverage**

### **Policy Engine Tests**
```
âœ… Policy Evaluation: User roles, resource access, parameter validation
âœ… Rate Limiting: Global, per-user, per-resource limits
âœ… Violation Recording: Security and policy violations
âœ… Compliance Metrics: Success rates, violation tracking
âœ… Audit Trail: Complete activity logging
âœ… Parameter Validation: Allowed/forbidden parameters
```

### **MCP Tools Tests**
```
âœ… Database Tools: Search, schema, query execution
âœ… Analytics Tools: Data analysis, report generation
âœ… Document Tools: Document processing, search
âœ… System Tools: System info, health checks, tool listing
âœ… SageAI Agent Tools: List, details, invoke agents
âœ… SageAI Tool Tools: List, details, execute tools
```

### **SageAI Integration Tests**
```
âœ… SageAI Agent Integration: Platform agent calls
âœ… SageAI Tool Integration: Platform tool calls
âœ… Policy Enforcement: Real-time governance
âœ… Compliance Monitoring: Metrics and audit trails
âœ… Token Validation: Authentication flow
âœ… Permission Checking: Role-based access control
```

---

## **ğŸ“ˆ Test Results**

### **Test Reports Generated**
- **`comprehensive_test_report.json`**: Complete test results
- **`policy_engine_test_report.json`**: Policy engine specific results
- **`mcp_tools_test_report.json`**: MCP tools specific results
- **`test_report.json`**: SageAI integration results

### **Report Format**
```json
{
  "timestamp": "2024-01-01T00:00:00Z",
  "test_duration_seconds": 45.2,
  "total_tests": 25,
  "passed_tests": 23,
  "failed_tests": 2,
  "success_rate": 92.0,
  "suite_results": {
    "policy_engine": true,
    "mcp_tools": true,
    "sageai_integration": false
  },
  "category_breakdown": {
    "policy": {"total": 8, "passed": 8, "failed": 0},
    "database": {"total": 3, "passed": 3, "failed": 0},
    "sageai": {"total": 6, "passed": 4, "failed": 2}
  }
}
```

---

## **ğŸ” Test Scenarios**

### **Policy Engine Scenarios**
1. **Admin Access**: Full access to all resources
2. **Agent User Access**: Limited to specific agents
3. **Tool User Access**: Limited to specific tools
4. **Restricted User**: Denied access to all resources
5. **Parameter Validation**: Allowed/forbidden parameters
6. **Rate Limiting**: Global and per-user limits
7. **Violation Recording**: Security violations
8. **Compliance Metrics**: Success rates and monitoring

### **SageAI Integration Scenarios**
1. **Agent Listing**: Retrieve available SageAI agents
2. **Agent Details**: Get specific agent information
3. **Agent Invocation**: Execute SageAI agents
4. **Tool Listing**: Retrieve available SageAI tools
5. **Tool Details**: Get specific tool information
6. **Tool Execution**: Execute SageAI tools
7. **Policy Enforcement**: Real-time governance
8. **Compliance Monitoring**: Metrics and audit trails

### **MCP Tools Scenarios**
1. **Database Operations**: Search, schema, queries
2. **Analytics Operations**: Data analysis, reports
3. **Document Operations**: Processing, search
4. **System Operations**: Info, health, tool listing
5. **SageAI Operations**: Agent and tool management

---

## **ğŸ› ï¸ Mock Data**

### **Mock SageAI Agents**
```json
[
  {
    "id": "agent_001",
    "name": "Data Analysis Agent",
    "status": "active",
    "description": "Analyzes data and generates insights"
  },
  {
    "id": "agent_003",
    "name": "Report Generator Agent",
    "status": "active",
    "description": "Generates comprehensive reports"
  }
]
```

### **Mock SageAI Tools**
```json
[
  {
    "id": "tool_analytics",
    "name": "Analytics Tool",
    "description": "Performs data analytics operations",
    "status": "active"
  },
  {
    "id": "tool_database",
    "name": "Database Tool",
    "description": "Executes database queries",
    "status": "active"
  }
]
```

### **Mock Policy Configuration**
```yaml
sageai_governance:
  enabled: true
  agents:
    allow_list: ["agent_001", "agent_003", "agent_005"]
    deny_list: ["agent_002", "agent_004"]
  tools:
    allow_list: ["tool_analytics", "tool_database"]
  users:
    role_based_access:
      admin: { agents: ["*"], tools: ["*"] }
      agent_user: { agents: ["agent_001", "agent_003"] }
      tool_user: { tools: ["tool_analytics", "tool_database"] }
```

---

## **âš¡ Performance Testing**

### **Policy Engine Performance**
- **Policy Evaluation**: < 10ms per request
- **Rate Limiting**: Sub-millisecond checks
- **Parameter Validation**: < 5ms per request
- **Compliance Metrics**: < 1ms retrieval

### **SageAI Integration Performance**
- **Agent Listing**: < 100ms (mocked)
- **Agent Invocation**: < 500ms (mocked)
- **Tool Execution**: < 200ms (mocked)
- **Policy Enforcement**: < 10ms per request

### **MCP Tools Performance**
- **Database Operations**: < 50ms (mocked)
- **Analytics Operations**: < 100ms (mocked)
- **Document Operations**: < 150ms (mocked)
- **System Operations**: < 10ms

---

## **ğŸ”§ Troubleshooting**

### **Common Issues**

#### **Import Errors**
```bash
# Ensure src is in Python path
export PYTHONPATH="${PYTHONPATH}:$(pwd)/../src"
python test_policy_engine_standalone.py
```

#### **Mock Function Issues**
```bash
# Check mock function setup
python -c "from test_sageai_integration import SageAIIntegrationTester; print('Mocks loaded')"
```

#### **Policy Engine Issues**
```bash
# Test policy engine initialization
python -c "import asyncio; from src.core.policy_engine import policy_engine; asyncio.run(policy_engine.initialize())"
```

### **Debug Mode**
```bash
# Enable debug logging
export LOG_LEVEL=DEBUG
python run_all_tests.py
```

---

## **ğŸ“‹ Test Checklist**

### **Before Running Tests**
- [ ] Python 3.8+ installed
- [ ] All dependencies installed (`pip install -r requirements.txt`)
- [ ] Source code in `../src` directory
- [ ] Test files in `tests` directory

### **After Running Tests**
- [ ] All test suites completed
- [ ] Success rate > 90%
- [ ] No critical failures
- [ ] Test reports generated
- [ ] Mock data working correctly

### **Production Readiness**
- [ ] Policy engine working correctly
- [ ] All MCP tools functional
- [ ] SageAI integration operational
- [ ] Policy enforcement active
- [ ] Compliance monitoring working
- [ ] Audit trail functional

---

## **ğŸ¯ Benefits**

### **âœ… No Infrastructure Required**
- **No Docker**: Run tests locally
- **No Server**: Direct component testing
- **No Database**: Mock data and responses
- **No Network**: All API calls mocked

### **âœ… Comprehensive Coverage**
- **Policy Engine**: Complete governance testing
- **MCP Tools**: All tool categories tested
- **SageAI Integration**: Platform integration verified
- **Compliance**: Monitoring and audit testing

### **âœ… Fast Execution**
- **Local Testing**: No network delays
- **Mock Responses**: Instant API responses
- **Parallel Execution**: Multiple test suites
- **Quick Feedback**: Immediate results

### **âœ… Production Confidence**
- **Real Scenarios**: Production-like test cases
- **Error Handling**: Exception testing
- **Performance**: Response time validation
- **Security**: Policy enforcement testing

---

## **ğŸš€ Getting Started**

1. **Navigate to tests directory**
   ```bash
   cd enterprise-mcp-server/tests
   ```

2. **Run comprehensive tests**
   ```bash
   python run_all_tests.py
   ```

3. **Check test results**
   ```bash
   cat comprehensive_test_report.json
   ```

4. **Review failed tests (if any)**
   ```bash
   grep -A 5 "FAIL" comprehensive_test_report.json
   ```

**ğŸ¯ This test suite ensures your SageAI MCP Server is production-ready with comprehensive testing of all components!**
